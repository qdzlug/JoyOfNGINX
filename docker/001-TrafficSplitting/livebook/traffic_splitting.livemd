# Traffic Splitting Demo

## Scenario

This notebook will help us explore the NGINX [ngx_http_split_clients_module](https://nginx.org/en/docs/http/ngx_http_split_clients_module.html) to understand how its applications and configuration options.

Imagine a situation where we have a very old application that sits outside our main architecture which we are going to try to replace with a totally new application that has been rewritten to our current standards but has the same interface:

<!-- livebook:{"break_markdown":true} -->

<!-- Learn more at https://mermaid-js.github.io/mermaid -->

```mermaid
graph TD;
  subgraph legacy infrastructure
    FRONTEND
    backend01
    backend02
  end
  subgraph new infrastructure
    backend03-canary
    DOWNSTREAM_SERVICE-->FRONTEND
  end

  FRONTEND-- * -->backend01;
  FRONTEND-- * -->backend02;
  FRONTEND-- 20% -->backend03-canary;
```

<!-- livebook:{"break_markdown":true} -->

We'd like to start routing a small amount of traffic to this new service as we monitor it carefully for scaling issues and bugs.

The easiest method is to leverage the existing NGINX reverse proxy that sits in front of the legacy service.

### Next Steps

1. Run the cells one by one in the "Setup" section. These just set up behind the scenes code for tracking request distribution
2. Use the cells in the "Visualizing Traffic Flow" section to run requests and see how they are distributed.

## Setup

The following installs libraries we'll need to show the data. It will take a bit to run the first time, but subsequent runs should be faster.

For each cell, click "evaluate" which will appear as you hover over the cell on the upper left.  Wait until the evaluation has completed before moving on to the next cell.

```elixir
Mix.install([
  {:smart_cell_command, path: "/data/smart_cell_command"},
  {:jason, "~> 1.4"},
  {:vega_lite, "~> 0.1"},
  {:kino_vega_lite, "~> 0.1"},
  {:dns, "~> 2.4"},
  {:smart_cell_file_editor, path: "/data/smart_cell_file_editor"}
])
```

<!-- livebook:{"attrs":{"filepath":"/etc/nginx/nginx.conf","file_content":"\nuser  nginx;\nworker_processes  auto;\n\nerror_log  /var/log/nginx/error.log notice;\npid        /var/run/nginx.pid;\n\n\nevents {\n    worker_connections  1024;\n}\n\n\nhttp {\n    include       /etc/nginx/mime.types;\n    default_type  application/octet-stream;\n\n    log_format main3 escape=json '{'\n    '\"remote_addr\":\"$remote_addr\",'\n    '\"time_iso8601\":\"$time_iso8601\",'\n    '\"request_uri\":\"$request_uri\",'\n    '\"request_length\":\"$request_length\",'\n    '\"request_method\":\"$request_method\",'\n    '\"request_time\":\"$request_time\",'\n    '\"server_port\":\"$server_port\",'\n    '\"server_protocol\":\"$server_protocol\",'\n    '\"ssl_protocol\":\"$ssl_protocol\",'\n    '\"status\":\"$status\",'\n    '\"bytes_sent\":\"$bytes_sent\",'\n    '\"http_referer\":\"$http_referer\",'\n    '\"http_user_agent\":\"$http_user_agent\",'\n    '\"upstream_response_time\":\"$upstream_response_time\",'\n    '\"upstream_addr\":\"$upstream_addr\",'\n    '\"upstream_connect_time\":\"$upstream_connect_time\",'\n    '\"upstream_cache_status\":\"$upstream_cache_status\",'\n    '\"tcpinfo_rtt\":\"$tcpinfo_rtt\",'\n    '\"tcpinfo_rttvar\":\"$tcpinfo_rttvar\"'\n    '}';\n\n\n\n    access_log  /var/log/nginx/access.log  main3;\n\n    sendfile        on;\n    #tcp_nopush     on;\n\n    keepalive_timeout  65;\n\n\n    upstream backend_prod {\n        zone backend_prod 64k;\n        server backend01:80;\n        server backend02:80;\n    }\n\n    upstream backend_preprod {\n        zone backend_preprod 64k;\n        server backend03:80;\n    }\n\n    split_clients \"${request_id}\" $backend_key {\n        80.0%   \"backend_preprod\";\n        *       \"backend_prod\";\n    }\n\n    server {\n        listen 80 default_server;\n        server_name $hostname;\n\n        location / {\n        proxy_set_header Dog-Name \"kishi\";\n        proxy_pass    http://$backend_key;\n        }\n}\n\n}\n"},"chunks":null,"kind":"Elixir.SmartCellFileEditor","livebook_object":"smart_cell"} -->

```elixir
"\nuser  nginx;\nworker_processes  auto;\n\nerror_log  /var/log/nginx/error.log notice;\npid        /var/run/nginx.pid;\n\n\nevents {\n    worker_connections  1024;\n}\n\n\nhttp {\n    include       /etc/nginx/mime.types;\n    default_type  application/octet-stream;\n\n    log_format main3 escape=json '{'\n    '\"remote_addr\":\"$remote_addr\",'\n    '\"time_iso8601\":\"$time_iso8601\",'\n    '\"request_uri\":\"$request_uri\",'\n    '\"request_length\":\"$request_length\",'\n    '\"request_method\":\"$request_method\",'\n    '\"request_time\":\"$request_time\",'\n    '\"server_port\":\"$server_port\",'\n    '\"server_protocol\":\"$server_protocol\",'\n    '\"ssl_protocol\":\"$ssl_protocol\",'\n    '\"status\":\"$status\",'\n    '\"bytes_sent\":\"$bytes_sent\",'\n    '\"http_referer\":\"$http_referer\",'\n    '\"http_user_agent\":\"$http_user_agent\",'\n    '\"upstream_response_time\":\"$upstream_response_time\",'\n    '\"upstream_addr\":\"$upstream_addr\",'\n    '\"upstream_connect_time\":\"$upstream_connect_time\",'\n    '\"upstream_cache_status\":\"$upstream_cache_status\",'\n    '\"tcpinfo_rtt\":\"$tcpinfo_rtt\",'\n    '\"tcpinfo_rttvar\":\"$tcpinfo_rttvar\"'\n    '}';\n\n\n\n    access_log  /var/log/nginx/access.log  main3;\n\n    sendfile        on;\n    #tcp_nopush     on;\n\n    keepalive_timeout  65;\n\n\n    upstream backend_prod {\n        zone backend_prod 64k;\n        server backend01:80;\n        server backend02:80;\n    }\n\n    upstream backend_preprod {\n        zone backend_preprod 64k;\n        server backend03:80;\n    }\n\n    split_clients \"${request_id}\" $backend_key {\n        80.0%   \"backend_preprod\";\n        *       \"backend_prod\";\n    }\n\n    server {\n        listen 80 default_server;\n        server_name $hostname;\n\n        location / {\n        proxy_set_header Dog-Name \"kishi\";\n        proxy_pass    http://$backend_key;\n        }\n}\n\n}\n"
|> IO.puts()
```

<!-- livebook:{"attrs":{"command":"curl -X POST --unix-socket /var/run/docker.sock  http:/v1.24/containers/frontend/restart"},"chunks":null,"kind":"Elixir.SmartCellCommand","livebook_object":"smart_cell"} -->

```elixir
"curl -X POST --unix-socket /var/run/docker.sock  http:/v1.24/containers/frontend/restart"
|> String.split("\n")
|> Enum.map(fn line ->
  [cmd | args] = line |> String.split(" ")
  {result, _} = System.cmd(cmd, args)
  result |> String.trim()
end)
|> Enum.join("\n\n")
|> IO.puts()
```

<!-- livebook:{"attrs":{"command":"apt-get update"},"chunks":null,"kind":"Elixir.SmartCellCommand","livebook_object":"smart_cell"} -->

```elixir
"apt-get update"
|> String.split("\n")
|> Enum.map(fn line ->
  [cmd | args] = line |> String.split(" ")
  {result, _} = System.cmd(cmd, args)
  result |> String.trim()
end)
|> Enum.join("\n\n")
|> IO.puts()
```

<!-- livebook:{"attrs":{"command":"apt-get install -y curl"},"chunks":null,"kind":"Elixir.SmartCellCommand","livebook_object":"smart_cell"} -->

```elixir
"apt-get install -y curl"
|> String.split("\n")
|> Enum.map(fn line ->
  [cmd | args] = line |> String.split(" ")
  {result, _} = System.cmd(cmd, args)
  result |> String.trim()
end)
|> Enum.join("\n\n")
|> IO.puts()
```

## Data Tracking Setup

Next we set up two things:

1. An in-memory store to keep track of how many requests are routed to each backend
2. A simple UDP server to consume output from a logspout container that will collect logs from the demo containers.

You don't need to understand any of this code.

```elixir
# For easy modification of the Genserver, make sure it's killed before the cell is reevaluated
case Process.whereis(Stats) do
  pid when is_pid(pid) ->
    Process.exit(pid, :kill)

  _ ->
    :ok
end

defmodule Stats do
  use GenServer

  @impl true
  def init(:ok) do
    {:ok, %{}}
  end

  # Get the request counts formatted for charting
  # [{x: "192.168.0.1", y: 23}, ...]
  @impl true
  def handle_call(:for_chart, _from, stats) do
    data =
      Map.keys(stats)
      |> Enum.map(fn key ->
        %{x: key, y: Map.get(stats, key)}
      end)

    {:reply, data, stats}
  end

  # Raw data output
  @impl true
  def handle_call(:raw, _from, stats) do
    {:reply, stats, stats}
  end

  # Increments the count for one IP address
  @impl true
  def handle_cast({:increment, ip}, stats) do
    {_val, updated_stats} =
      Map.get_and_update(stats, ip, fn
        nil ->
          {nil, 1}

        current_value ->
          {current_value, current_value + 1}
      end)

    {:noreply, updated_stats}
  end

  # Clear the counter
  @impl true
  def handle_cast(:clear, _stats) do
    {:noreply, %{}}
  end
end

GenServer.start(Stats, :ok, name: Stats)
```

```elixir
# For easy modification of the Genserver, make sure it's killed before the cell is reevaluated
case Process.whereis(UDPServer) do
  pid when is_pid(pid) ->
    Process.exit(pid, :kill)

  _ ->
    :ok
end

# The following code is referenced from:
# https://gist.github.com/joshnuss/08603e11615ee0de65724be4d63354755
defmodule UDPServer do
  use GenServer

  def child_spec(opts) do
    %{
      id: UDPServer,
      start: {__MODULE__, :start_link, [opts]},
      shutdown: 5_000,
      restart: :transient,
      type: :worker
    }
  end

  def start_link(port \\ 2052) do
    GenServer.start_link(__MODULE__, port)
  end

  def init(port) do
    :gen_udp.open(port, [:binary, active: true])
  end

  def handle_info({:udp, _socket, _address, _port, data}, socket) do
    handle_packet(data, socket)
  end

  defp handle_packet("quit\n", socket) do
    IO.puts("Received: quit from udp")
    :gen_udp.close(socket)
    {:stop, :normal, nil}
  end

  # Handle the pertinent log entry from the frontend
  defp handle_packet(<<_preamble::bytes-size(55), msg::binary>>, socket) do
    case Jason.decode(msg) do
      {:ok, %{"upstream_addr" => upstream_addr}} ->
        GenServer.cast(Stats, {:increment, upstream_addr})

      _other ->
        :ok
    end

    {:noreply, socket}
  end

  # fallback pattern match to handle all other (non-"quit") messages
  defp handle_packet(_data, socket) do
    {:noreply, socket}
  end
end

GenServer.start(UDPServer, 514, name: UDPServer)
```

The following cell determines which IP addresses correspond to our named backends in order to make the diagrams easier to read.

```elixir
ip_to_name_mapping =
  ["backend01", "backend02", "backend03"]
  |> Enum.reduce(%{}, fn be, acc ->
    case DNS.resolve(be) do
      {:ok, [ip]} ->
        upstream_ip =
          Tuple.to_list(ip)
          |> Enum.join(".")

        Map.put(acc, "#{upstream_ip}:80", be)

      _err ->
        acc
    end
  end)
```

## Visualize Traffic Split

The following cell will send a request to our NGINX frontend. Run this many times, then scroll down to the visualizations to see how traffic is being distributed among the backends

<!-- livebook:{"attrs":{"command":"curl -s -o /dev/null frontend:80"},"chunks":null,"kind":"Elixir.SmartCellCommand","livebook_object":"smart_cell"} -->

```elixir
"curl -s -o /dev/null frontend:80"
|> String.split("\n")
|> Enum.map(fn line ->
  [cmd | args] = line |> String.split(" ")
  {result, _} = System.cmd(cmd, args)
  result |> String.trim()
end)
|> Enum.join("\n\n")
|> IO.puts()
```

### View as Flowchart

````elixir
data = GenServer.call(Stats, :raw)

text =
  ip_to_name_mapping
  |> Enum.reduce("", fn {ip, backend_name}, acc ->
    case Map.get(data, ip) do
      nil ->
        acc <> "FRONTEND-- 0 -->#{backend_name};\n"

      call_count ->
        acc <> "FRONTEND-- #{call_count} -->#{backend_name};\n"
    end
  end)

Kino.Markdown.new(~s"""
```mermaid
graph LR;
    FRONTEND;
    #{text}
```
""")
````

### View as Bar Chart

```elixir
alias VegaLite, as: Vl
raw_data = GenServer.call(Stats, :raw)

data =
  ip_to_name_mapping
  |> Enum.map(fn {ip, name} ->
    %{x: name, y: Map.get(raw_data, ip, 0)}
  end)

widget =
  Vl.new(width: 400, height: 300)
  |> Vl.data_from_values(data)
  |> Vl.mark(:bar)
  |> Vl.encode_field(:x, "x", type: :nominal, axis: [label_angle: 0])
  |> Vl.encode_field(:y, "y", type: :quantitative)
```

<!-- livebook:{"attrs":{"filepath":"/etc/nginx/nginx.conf","file_content":"\nuser  nginx;\nworker_processes  auto;\n\nerror_log  /var/log/nginx/error.log notice;\npid        /var/run/nginx.pid;\n\n\nevents {\n    worker_connections  1024;\n}\n\n\nhttp {\n    include       /etc/nginx/mime.types;\n    default_type  application/octet-stream;\n\n    log_format main3 escape=json '{'\n    '\"remote_addr\":\"$remote_addr\",'\n    '\"time_iso8601\":\"$time_iso8601\",'\n    '\"request_uri\":\"$request_uri\",'\n    '\"request_length\":\"$request_length\",'\n    '\"request_method\":\"$request_method\",'\n    '\"request_time\":\"$request_time\",'\n    '\"server_port\":\"$server_port\",'\n    '\"server_protocol\":\"$server_protocol\",'\n    '\"ssl_protocol\":\"$ssl_protocol\",'\n    '\"status\":\"$status\",'\n    '\"bytes_sent\":\"$bytes_sent\",'\n    '\"http_referer\":\"$http_referer\",'\n    '\"http_user_agent\":\"$http_user_agent\",'\n    '\"upstream_response_time\":\"$upstream_response_time\",'\n    '\"upstream_addr\":\"$upstream_addr\",'\n    '\"upstream_connect_time\":\"$upstream_connect_time\",'\n    '\"upstream_cache_status\":\"$upstream_cache_status\",'\n    '\"tcpinfo_rtt\":\"$tcpinfo_rtt\",'\n    '\"tcpinfo_rttvar\":\"$tcpinfo_rttvar\"'\n    '}';\n\n\n\n    access_log  /var/log/nginx/access.log  main3;\n\n    sendfile        on;\n    #tcp_nopush     on;\n\n    keepalive_timeout  65;\n\n\n    upstream backend_prod {\n        zone backend_prod 64k;\n        server backend01:80;\n        server backend02:80;\n    }\n\n    upstream backend_preprod {\n        zone backend_preprod 64k;\n        server backend03:80;\n    }\n\n    split_clients \"${time_iso8601}\" $backend_key {\n        20.0%   \"backend_preprod\";\n        *       \"backend_prod\";\n    }\n\n    server {\n        listen 80 default_server;\n        server_name $hostname;\n\n        location / {\n        proxy_set_header Dog-Name \"kishi\";\n        proxy_pass    http://$backend_key;\n        }\n}\n\n}\n"},"chunks":null,"kind":"Elixir.SmartCellFileEditor","livebook_object":"smart_cell"} -->

```elixir
"\nuser  nginx;\nworker_processes  auto;\n\nerror_log  /var/log/nginx/error.log notice;\npid        /var/run/nginx.pid;\n\n\nevents {\n    worker_connections  1024;\n}\n\n\nhttp {\n    include       /etc/nginx/mime.types;\n    default_type  application/octet-stream;\n\n    log_format main3 escape=json '{'\n    '\"remote_addr\":\"$remote_addr\",'\n    '\"time_iso8601\":\"$time_iso8601\",'\n    '\"request_uri\":\"$request_uri\",'\n    '\"request_length\":\"$request_length\",'\n    '\"request_method\":\"$request_method\",'\n    '\"request_time\":\"$request_time\",'\n    '\"server_port\":\"$server_port\",'\n    '\"server_protocol\":\"$server_protocol\",'\n    '\"ssl_protocol\":\"$ssl_protocol\",'\n    '\"status\":\"$status\",'\n    '\"bytes_sent\":\"$bytes_sent\",'\n    '\"http_referer\":\"$http_referer\",'\n    '\"http_user_agent\":\"$http_user_agent\",'\n    '\"upstream_response_time\":\"$upstream_response_time\",'\n    '\"upstream_addr\":\"$upstream_addr\",'\n    '\"upstream_connect_time\":\"$upstream_connect_time\",'\n    '\"upstream_cache_status\":\"$upstream_cache_status\",'\n    '\"tcpinfo_rtt\":\"$tcpinfo_rtt\",'\n    '\"tcpinfo_rttvar\":\"$tcpinfo_rttvar\"'\n    '}';\n\n\n\n    access_log  /var/log/nginx/access.log  main3;\n\n    sendfile        on;\n    #tcp_nopush     on;\n\n    keepalive_timeout  65;\n\n\n    upstream backend_prod {\n        zone backend_prod 64k;\n        server backend01:80;\n        server backend02:80;\n    }\n\n    upstream backend_preprod {\n        zone backend_preprod 64k;\n        server backend03:80;\n    }\n\n    split_clients \"${time_iso8601}\" $backend_key {\n        20.0%   \"backend_preprod\";\n        *       \"backend_prod\";\n    }\n\n    server {\n        listen 80 default_server;\n        server_name $hostname;\n\n        location / {\n        proxy_set_header Dog-Name \"kishi\";\n        proxy_pass    http://$backend_key;\n        }\n}\n\n}\n"
|> IO.puts()
```

## Clean Up

```elixir
GenServer.cast(Stats, :clear)
```
